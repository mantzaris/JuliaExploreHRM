{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d72de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaacb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/repos/JuliaExploreHRM`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")  #one level up, where Project.toml lives\n",
    "Pkg.instantiate()   #download/install anything missing\n",
    "# Pkg.status();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6261d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module BooleanDataGenerator.\n",
      "WARNING: replacing module HRMFlux.\n",
      "WARNING: using BooleanDataGenerator.generate_data in module Main conflicts with an existing identifier.\n",
      "WARNING: using HRMFlux.TransformerBlock in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "include(joinpath(@__DIR__, \"..\", \"data\", \"nested_boolean_gen.jl\"))\n",
    "include(joinpath(@__DIR__, \"..\", \"data\", \"hrm_common_nested_boolean_FLUX.jl\"))\n",
    "\n",
    "using .BooleanDataGenerator\n",
    "using .HRMFlux\n",
    "\n",
    "using StatsBase\n",
    "using Random, Statistics\n",
    "using Flux, Zygote, Optimisers\n",
    "using Flux: onehotbatch, onecold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a877509f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1 1 … 1 1; 1 0 … 0 0; … ; 0 1 … 1 0; 0 1 … 0 1], [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1], [\"(NOT (AND x1 (XOR x1 x1)))\", \"(AND x5 x2)\", \"(NOT x3)\", \"(OR x2 x4)\", \"(OR x2 (AND x3 x3))\", \"(XOR (OR x2 x4) (XOR x3 x2))\", \"(XOR x2 x5)\", \"(OR x2 x4)\", \"(NOT (AND x3 (OR x4 x5)))\", \"(OR x2 x5)\", \"(OR x3 (OR x4 x5))\", \"(AND x4 (AND (XOR x4 x3) x3))\", \"(OR x1 (OR x1 x3))\", \"(OR x5 x2)\", \"(OR x4 x1)\", \"(AND (AND x2 (XOR x2 x4)) (AND x1 x1))\", \"(NOT x1)\", \"(OR x5 (OR x1 x4))\", \"(XOR x3 (NOT x5))\", \"(OR (NOT x5) (OR x1 x2))\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training data (depth 2-4)\n",
    "X_train, y_trainainainain, _ = generate_data(100; min_depth=2, max_depth=4)\n",
    "\n",
    "# Test data (depth 5-8) \n",
    "X_test, y_test, _ = generate_data(20; min_depth=5, max_depth=8)\n",
    "\n",
    "# Test data (held-out NAND)\n",
    "X_test_ops, y_test_ops, _ = generate_data(20; held_out_ops=[:NAND])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce810bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: X=(100, 5), y=(100,)\n",
      "Test (depth): X=(20, 5), y=(20,)\n",
      "Test (ops): X=(20, 5), y=(20,)\n",
      "\n",
      "Training examples:\n",
      "(NOT (AND x1 (NAND x1 x1))) | vars=[1, 1, 1, 1, 1] → 1\n",
      "(AND x5 x2) | vars=[1, 0, 0, 0, 0] → 0\n",
      "(NOT x3) | vars=[1, 1, 1, 0, 1] → 0\n"
     ]
    }
   ],
   "source": [
    "# Generate training data (depth 2-4)\n",
    "X_train, y_train, expr_train = generate_data(100; min_depth=2, max_depth=4, seed=42)\n",
    "\n",
    "# Generate test data with depth generalization (depth 5-8)\n",
    "X_test, y_test, expr_test = generate_data(20; min_depth=5, max_depth=8, seed=123)\n",
    "\n",
    "# Generate test data with held-out operations (no NAND)\n",
    "X_test_ops, y_test_ops, expr_test_ops = generate_data(20; held_out_ops=[:NAND], seed=456)\n",
    "\n",
    "println(\"Training: X=$(size(X_train)), y=$(size(y_train))\")\n",
    "println(\"Test (depth): X=$(size(X_test)), y=$(size(y_test))\")\n",
    "println(\"Test (ops): X=$(size(X_test_ops)), y=$(size(y_test_ops))\")\n",
    "\n",
    "# Show a few examples\n",
    "println(\"\\nTraining examples:\")\n",
    "for i in 1:3\n",
    "    println(\"$(expr_train[i]) | vars=$(X_train[i,:]) → $(y_train[i])\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee8a752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0 1 … 0 1; 0 0 … 1 1; … ; 1 0 … 0 0; 0 1 … 0 0], [1, 0, 1, 1, 1, 1, 1, 0, 1, 1  …  1, 1, 0, 1, 1, 0, 1, 0, 0, 0], [\"(OR (NAND (NOT (NAND x1 x5)) (XOR x6 (AND x2 x5))) (AND x5 x6))\", \"(NOT (NOT (OR x3 (OR x1 x3))))\", \"(XOR x5 (OR (XOR x4 (OR x6 x2)) x3))\", \"(NAND (OR (OR x3 x3) (NAND x1 x2)) (XOR (NAND (XOR x2 x2) x6) (OR x4 (NOT x2))))\", \"(NAND (NAND (NAND (OR x1 x3) (NOT x5)) x5) (NAND x4 x1))\", \"(NOT (XOR (NAND x6 (XOR x2 x1)) x4))\", \"(NOT (NOT (OR (NAND x1 x6) x5)))\", \"(AND x4 (OR (NAND x5 (NAND x6 x3)) (NOT (OR x4 x6))))\", \"(OR (XOR (XOR x4 (NAND x3 x3)) (AND x2 x3)) (NAND x2 x3))\", \"(NAND (XOR x5 x5) (XOR x4 (NOT (NAND x6 x4))))\"  …  \"(NAND x3 (AND (XOR (NAND x4 x3) x3) x5))\", \"(NAND (NAND x6 (XOR x6 x2)) (NOT (NOT (AND x3 x1))))\", \"(XOR (NAND x6 (NAND (XOR x6 x5) (NAND x4 x3))) (XOR x6 x2))\", \"(XOR x2 (OR (NAND x6 (NAND x4 x1)) (AND x4 x2)))\", \"(OR x5 (NOT (XOR (NAND x1 x2) x6)))\", \"(AND (NOT (XOR x2 (OR x4 x6))) (XOR x4 (XOR (AND x4 x2) (AND x6 (NAND x1 x1)))))\", \"(NOT (NOT (NAND (XOR x6 x4) (XOR x5 x2))))\", \"(AND x6 (NAND (AND (NOT x5) (AND x1 x6)) (NOT (NAND x4 x6))))\", \"(NOT (XOR (XOR x3 x6) (OR (OR x5 x4) (NOT x4))))\", \"(NOT (NAND (AND (AND x4 x5) (AND x5 x5)) (XOR x6 x3)))\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train (depth 2-4), Test-ID (2-4), Test-OOD (5-8)\n",
    "X_train, y_train, expr_train = BooleanDataGenerator.generate_data(2000; variable_count=6, min_depth=2, max_depth=4, seed=1)\n",
    "X_id,    y_test_id,    expr_id    = BooleanDataGenerator.generate_data(500;  variable_count=6, min_depth=2, max_depth=4, seed=2)\n",
    "X_ood,   y_ood,   expr_ood   = BooleanDataGenerator.generate_data(500;  variable_count=6, min_depth=5, max_depth=8, seed=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c86bec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Vector{Vector{String}}:\n",
       " [\"OR\", \"NAND\", \"NOT\", \"NAND\", \"x1=0\", \"x5=0\", \"XOR\", \"x6=1\", \"AND\", \"x2=1\", \"x5=0\", \"AND\", \"x5=0\", \"x6=1\"]\n",
       " [\"NOT\", \"NOT\", \"OR\", \"x3=0\", \"OR\", \"x1=0\", \"x3=0\"]\n",
       " [\"XOR\", \"x5=0\", \"OR\", \"XOR\", \"x4=0\", \"OR\", \"x6=0\", \"x2=1\", \"x3=0\"]\n",
       " [\"NAND\", \"OR\", \"OR\", \"x3=1\", \"x3=1\", \"NAND\", \"x1=1\", \"x2=0\", \"XOR\", \"NAND\", \"XOR\", \"x2=0\", \"x2=0\", \"x6=0\", \"OR\", \"x4=1\", \"NOT\", \"x2=0\"]\n",
       " [\"NAND\", \"NAND\", \"NAND\", \"OR\", \"x1=0\", \"x3=0\", \"NOT\", \"x5=1\", \"x5=1\", \"NAND\", \"x4=0\", \"x1=0\"]\n",
       " [\"NOT\", \"XOR\", \"NAND\", \"x6=1\", \"XOR\", \"x2=1\", \"x1=1\", \"x4=1\"]\n",
       " [\"NOT\", \"NOT\", \"OR\", \"NAND\", \"x1=1\", \"x6=1\", \"x5=1\"]\n",
       " [\"AND\", \"x4=0\", \"OR\", \"NAND\", \"x5=0\", \"NAND\", \"x6=1\", \"x3=1\", \"NOT\", \"OR\", \"x4=0\", \"x6=1\"]\n",
       " [\"OR\", \"XOR\", \"XOR\", \"x4=0\", \"NAND\", \"x3=1\", \"x3=1\", \"AND\", \"x2=0\", \"x3=1\", \"NAND\", \"x2=0\", \"x3=1\"]\n",
       " [\"NAND\", \"XOR\", \"x5=0\", \"x5=0\", \"XOR\", \"x4=0\", \"NOT\", \"NAND\", \"x6=1\", \"x4=0\"]\n",
       " ⋮\n",
       " [\"NAND\", \"NAND\", \"x6=0\", \"XOR\", \"x6=0\", \"x2=1\", \"NOT\", \"NOT\", \"AND\", \"x3=0\", \"x1=0\"]\n",
       " [\"XOR\", \"NAND\", \"x6=0\", \"NAND\", \"XOR\", \"x6=0\", \"x5=0\", \"NAND\", \"x4=0\", \"x3=1\", \"XOR\", \"x6=0\", \"x2=1\"]\n",
       " [\"XOR\", \"x2=1\", \"OR\", \"NAND\", \"x6=1\", \"NAND\", \"x4=0\", \"x1=0\", \"AND\", \"x4=0\", \"x2=1\"]\n",
       " [\"OR\", \"x5=0\", \"NOT\", \"XOR\", \"NAND\", \"x1=1\", \"x2=0\", \"x6=1\"]\n",
       " [\"AND\", \"NOT\", \"XOR\", \"x2=0\", \"OR\", \"x4=1\", \"x6=0\", \"XOR\", \"x4=1\", \"XOR\", \"AND\", \"x4=1\", \"x2=0\", \"AND\", \"x6=0\", \"NAND\", \"x1=0\", \"x1=0\"]\n",
       " [\"NOT\", \"NOT\", \"NAND\", \"XOR\", \"x6=1\", \"x4=1\", \"XOR\", \"x5=1\", \"x2=1\"]\n",
       " [\"AND\", \"x6=0\", \"NAND\", \"AND\", \"NOT\", \"x5=0\", \"AND\", \"x1=0\", \"x6=0\", \"NOT\", \"NAND\", \"x4=0\", \"x6=0\"]\n",
       " [\"NOT\", \"XOR\", \"XOR\", \"x3=0\", \"x6=0\", \"OR\", \"OR\", \"x5=0\", \"x4=1\", \"NOT\", \"x4=1\"]\n",
       " [\"NOT\", \"NAND\", \"AND\", \"AND\", \"x4=0\", \"x5=0\", \"AND\", \"x5=0\", \"x5=0\", \"XOR\", \"x6=0\", \"x3=0\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function tokenize_with_assignment(expression::String, variable_row::AbstractVector{<:Integer})\n",
    "    spaced = replace(expression, r\"([()])\" => s\" \\1 \")\n",
    "    raw_tokens = split(strip(spaced))\n",
    "    tokens = String[]\n",
    "    for t in raw_tokens\n",
    "        if startswith(t, \"x\")\n",
    "            idx = parse(Int, t[2:end])\n",
    "            push!(tokens, \"x$(idx)=$(variable_row[idx])\")\n",
    "        elseif t == \"(\" || t == \")\"\n",
    "            continue  # drop parentheses to shorten sequences\n",
    "        else\n",
    "            push!(tokens, t)  # \"AND\", \"OR\", \"XOR\", \"NAND\", \"NOT\"\n",
    "        end\n",
    "    end\n",
    "    return tokens\n",
    "end\n",
    "\n",
    "\n",
    "# Build token sequences\n",
    "function build_token_sequences(expressions::Vector{String}, X::Array{Int,2})\n",
    "    seqs = Vector{Vector{String}}(undef, length(expressions))\n",
    "    for i in eachindex(expressions)\n",
    "        seqs[i] = tokenize_with_assignment(expressions[i], vec(X[i, :]))\n",
    "    end\n",
    "    return seqs\n",
    "end\n",
    "\n",
    "train_tokens = build_token_sequences(expr_train, X_train)\n",
    "id_tokens    = build_token_sequences(expr_id,    X_id)\n",
    "ood_tokens   = build_token_sequences(expr_ood,   X_ood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6bebf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Vector{Vector{Int64}}:\n",
       " [6, 9, 14, 9, 15, 3, 12, 2, 1, 10, 3, 1, 3, 2]\n",
       " [14, 14, 6, 13, 6, 15, 13]\n",
       " [12, 3, 6, 12, 11, 6, 7, 10, 13]\n",
       " [9, 6, 6, 8, 8, 9, 17, 4, 12, 9, 12, 4, 4, 7, 6, 5, 14, 4]\n",
       " [9, 9, 9, 6, 15, 13, 14, 16, 16, 9, 11, 15]\n",
       " [14, 12, 9, 2, 12, 10, 17, 5]\n",
       " [14, 14, 6, 9, 17, 2, 16]\n",
       " [1, 11, 6, 9, 3, 9, 2, 8, 14, 6, 11, 2]\n",
       " [6, 12, 12, 11, 9, 8, 8, 1, 4, 8, 9, 4, 8]\n",
       " [9, 12, 3, 3, 12, 11, 14, 9, 2, 11]\n",
       " ⋮\n",
       " [9, 9, 7, 12, 7, 10, 14, 14, 1, 13, 15]\n",
       " [12, 9, 7, 9, 12, 7, 3, 9, 11, 8, 12, 7, 10]\n",
       " [12, 10, 6, 9, 2, 9, 11, 15, 1, 11, 10]\n",
       " [6, 3, 14, 12, 9, 17, 4, 2]\n",
       " [1, 14, 12, 4, 6, 5, 7, 12, 5, 12, 1, 5, 4, 1, 7, 9, 15, 15]\n",
       " [14, 14, 9, 12, 2, 5, 12, 16, 10]\n",
       " [1, 7, 9, 1, 14, 3, 1, 15, 7, 14, 9, 11, 7]\n",
       " [14, 12, 12, 13, 7, 6, 6, 3, 5, 14, 5]\n",
       " [14, 9, 1, 1, 11, 3, 1, 3, 3, 12, 7, 13]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vocabulary from training tokens only\n",
    "function build_vocab(token_sequences::Vector{Vector{String}})\n",
    "    vocab = Dict{String,Int}()\n",
    "    next_id = 1\n",
    "    for seq in token_sequences\n",
    "        for t in seq\n",
    "            if !haskey(vocab, t)\n",
    "                vocab[t] = next_id\n",
    "                next_id += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return vocab\n",
    "end\n",
    "\n",
    "vocab = build_vocab(train_tokens)\n",
    "unk_id = length(vocab) + 1  # just in case (should not be needed here)\n",
    "\n",
    "# Map tokens to integer ids\n",
    "token_to_id_tmp = t -> get(vocab, t, unk_id)\n",
    "function map_to_ids(token_sequences::Vector{Vector{String}})\n",
    "    return [map(token_to_id_tmp, seq) for seq in token_sequences]\n",
    "end\n",
    "\n",
    "train_ids = map_to_ids(train_tokens)\n",
    "id_ids    = map_to_ids(id_tokens)\n",
    "ood_ids   = map_to_ids(ood_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f45d188b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1644ab32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8505a5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc0c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatsBase.countmap(depths(expr_tr_A)) = Dict(4 => 668, 2 => 666, 3 => 666)\n",
      "StatsBase.countmap(depths(expr_tr_B)) = Dict(5 => 800, 4 => 800, 6 => 800, 2 => 800, 3 => 800)\n",
      "StatsBase.countmap(depths(expr_te_ID)) = Dict(4 => 334, 2 => 333, 3 => 333)\n",
      "StatsBase.countmap(depths(expr_te_MID)) = Dict(5 => 500, 6 => 500)\n",
      "StatsBase.countmap(depths(expr_te_OOD)) = Dict(7 => 500, 8 => 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch=1  loss=0.7071  ID(2-4)=0.554  MID(5-6)=0.611  OOD(7-8)=0.612\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.612\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=2  loss=0.6526  ID(2-4)=0.596  MID(5-6)=0.63  OOD(7-8)=0.631\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.631\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=3  loss=0.6447  ID(2-4)=0.69  MID(5-6)=0.628  OOD(7-8)=0.628\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.628\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=4  loss=0.582  ID(2-4)=0.772  MID(5-6)=0.631  OOD(7-8)=0.636\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.636\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=5  loss=0.4692  ID(2-4)=0.787  MID(5-6)=0.687  OOD(7-8)=0.655\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.655\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg = cfg) = Dict(7 => 0.658, 8 => 0.652)\n",
      "accuracy_by_depth(models, Xids_te_M, y_te_MID, expr_te_MID; cfg = cfg) = Dict(5 => 0.654, 6 => 0.72)\n",
      "Final depth bins (OOD 7-8):\n",
      "accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg = cfg) = Dict(7 => 0.658, 8 => 0.652)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch=6  loss=0.4287  ID(2-4)=0.817  MID(5-6)=0.669  OOD(7-8)=0.643\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.643\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=7  loss=0.3918  ID(2-4)=0.809  MID(5-6)=0.687  OOD(7-8)=0.678\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.678\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=8  loss=0.3715  ID(2-4)=0.843  MID(5-6)=0.668  OOD(7-8)=0.622\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.622\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=9  loss=0.3543  ID(2-4)=0.849  MID(5-6)=0.706  OOD(7-8)=0.671\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.671\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=10  loss=0.3498  ID(2-4)=0.873  MID(5-6)=0.677  OOD(7-8)=0.657\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.657\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg = cfg) = Dict(7 => 0.646, 8 => 0.668)\n",
      "accuracy_by_depth(models, Xids_te_M, y_te_MID, expr_te_MID; cfg = cfg) = Dict(5 => 0.692, 6 => 0.662)\n",
      "Final depth bins (OOD 7-8):\n",
      "accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg = cfg) = Dict(7 => 0.646, 8 => 0.668)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch=11  loss=0.3355  ID(2-4)=0.866  MID(5-6)=0.692  OOD(7-8)=0.665\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.665\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=12  loss=0.3179  ID(2-4)=0.856  MID(5-6)=0.701  OOD(7-8)=0.665\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.665\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=13  loss=0.3124  ID(2-4)=0.871  MID(5-6)=0.722  OOD(7-8)=0.676\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.676\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=14  loss=0.2986  ID(2-4)=0.874  MID(5-6)=0.719  OOD(7-8)=0.68\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.68\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=15  loss=0.2987  ID(2-4)=0.877  MID(5-6)=0.715  OOD(7-8)=0.679\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.679\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg = cfg) = Dict(7 => 0.678, 8 => 0.68)\n",
      "accuracy_by_depth(models, Xids_te_M, y_te_MID, expr_te_MID; cfg = cfg) = Dict(5 => 0.708, 6 => 0.722)\n",
      "Final depth bins (OOD 7-8):\n",
      "accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg = cfg) = Dict(7 => 0.678, 8 => 0.68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch=16  loss=0.2876  ID(2-4)=0.884  MID(5-6)=0.7  OOD(7-8)=0.686\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.686\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n",
      "┌ Info: epoch=17  loss=0.2789  ID(2-4)=0.893  MID(5-6)=0.712  OOD(7-8)=0.677\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:437\n",
      "┌ Info: OOD macro (7/8 equally) = 0.677\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:443\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      "  [1] macro expansion\n",
      "    @ ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0 [inlined]\n",
      "  [2] _pullback\n",
      "    @ ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:81 [inlined]\n",
      "  [3] Dense\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/basic.jl:199 [inlined]\n",
      "  [4] Dense\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/basic.jl:204 [inlined]\n",
      "  [5] _pullback(ctx::Zygote.Context{false}, f::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, args::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      "  [6] _applychain\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/basic.jl:68 [inlined]\n",
      "  [7] Chain\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/basic.jl:65 [inlined]\n",
      "  [8] _pullback(ctx::Zygote.Context{false}, f::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, args::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      "  [9] #forward_block#2\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_nested_boolean_FLUX.jl:123 [inlined]\n",
      " [10] _pullback(::Zygote.Context{false}, ::Main.HRMFlux.var\"##forward_block#2\", ::Nothing, ::typeof(Main.HRMFlux.forward_block), ::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, ::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [11] forward_block\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_nested_boolean_FLUX.jl:92 [inlined]\n",
      " [12] _pullback(::Zygote.Context{false}, ::typeof(Main.HRMFlux.forward_block), ::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, ::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [13] #run_sequence_segment!#8\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_nested_boolean_FLUX.jl:435 [inlined]\n",
      " [14] _pullback(::Zygote.Context{false}, ::Main.HRMFlux.var\"##run_sequence_segment!#8\", ::Int64, ::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}, ::Nothing, ::typeof(Main.HRMFlux.run_sequence_segment!), ::@NamedTuple{tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, raw_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hpost::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Matrix{Float32}, ::Matrix{Float32})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [15] run_sequence_segment!\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_nested_boolean_FLUX.jl:399 [inlined]\n",
      " [16] _pullback(::Zygote.Context{false}, ::typeof(Core.kwcall), ::@NamedTuple{N::Int64, cfg::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}}, ::typeof(Main.HRMFlux.run_sequence_segment!), ::@NamedTuple{tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, raw_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hpost::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Matrix{Float32}, ::Matrix{Float32})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [17] batch_loss\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:326 [inlined]\n",
      " [18] _pullback(::Zygote.Context{false}, ::typeof(batch_loss), ::@NamedTuple{tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, raw_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hpost::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Vector{Int64}, ::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [19] #286\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:423 [inlined]\n",
      " [20] _pullback(ctx::Zygote.Context{false}, f::var\"#286#287\"{Vector{Int64}, Matrix{Int64}}, args::@NamedTuple{tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, raw_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hpost::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [21] pullback(f::Function, cx::Zygote.Context{false}, args::@NamedTuple{tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, raw_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hpost::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface.jl:96\n",
      " [22] pullback(f::Function, args::@NamedTuple{tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, raw_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hblk::Main.HRMFlux.TransformerBlock{PositionalEmbeddings.AbsolutePE{Matrix{Float32}}}, Hpost::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface.jl:94\n",
      " [23] top-level scope\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/05_nested_arithmetic_expression_Flux/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:423"
     ]
    }
   ],
   "source": [
    "VARIABLE_COUNT = 6\n",
    "N_A   = 4000   # Train Phase A (2-4)\n",
    "N_B   = 8000   # Train Phase B (2-6)\n",
    "N_ID  = 1000   # Test (2-4)\n",
    "N_MID = 1000   # Test (5-6)\n",
    "N_OOD = 1000   # Test (7-8)\n",
    "\n",
    "Random.seed!(1)\n",
    "\n",
    "\n",
    "\n",
    "cfg = (\n",
    "    d_in   = 0,\n",
    "    d_hid  = 128,\n",
    "    d_out  = 1,\n",
    "    N      = 4,\n",
    "    T      = 0,\n",
    "    batch  = 32,\n",
    "    lr     = 1e-4,\n",
    "    num_tokens = length(vocab),\n",
    "    d_embed    = 128,\n",
    "    l_heads    = 4,\n",
    "    l_ff_mult  = 4,\n",
    "    h_heads    = 4,\n",
    "    h_ff_mult  = 4,\n",
    "    dropout    = 0.15,\n",
    "    pad_id     = PAD_ID\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "function make_depth_stratified_split(depth_counts::Dict{Int,Int};\n",
    "    variable_count::Int, seed::Int)\n",
    "\n",
    "    Xs = Matrix{Int}[]; ys = Vector{Int}[]; Es = Vector{String}[]\n",
    "    for d in sort(collect(keys(depth_counts)))\n",
    "        n = depth_counts[d]; n == 0 && continue\n",
    "        X, y, E = BooleanDataGenerator.generate_data(n;\n",
    "                            variable_count=variable_count, min_depth=d, max_depth=d, seed=seed + d,\n",
    "                            mode = :exact)\n",
    "        push!(Xs, X); push!(ys, y); push!(Es, E)\n",
    "    end\n",
    "    X_all = vcat(Xs...)                 # (N_total, variable_count)\n",
    "    y_all = reduce(vcat, ys)            # (N_total,)\n",
    "    E_all = reduce(vcat, Es)            # Vector{String} length N_total\n",
    "\n",
    "    # Shuffle ROWS (samples) — NOT columns\n",
    "    perm = randperm(size(X_all, 1))\n",
    "    return X_all[perm, :], y_all[perm], E_all[perm]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Train pools\n",
    "# Train Phase A: (2,3,4)\n",
    "X_tr_A, y_tr_A, expr_tr_A =\n",
    "    make_depth_stratified_split(Dict(2=>N_A÷3, 3=>N_A÷3, 4=>N_A - 2*(N_A÷3));\n",
    "                                variable_count=VARIABLE_COUNT, seed=101)\n",
    "\n",
    "# Train Phase B: (2,3,4,5,6) equal-ish\n",
    "X_tr_B, y_tr_B, expr_tr_B =\n",
    "    make_depth_stratified_split(Dict(2=>N_B÷5, 3=>N_B÷5, 4=>N_B÷5, 5=>N_B÷5, 6=>N_B - 4*(N_B÷5));\n",
    "                                variable_count=VARIABLE_COUNT, seed=102)\n",
    "\n",
    "# Test ID: (2,3,4)\n",
    "X_te_ID,  y_te_ID,  expr_te_ID  =\n",
    "    make_depth_stratified_split(Dict(2=>N_ID÷3, 3=>N_ID÷3, 4=>N_ID - 2*(N_ID÷3));\n",
    "                                variable_count=VARIABLE_COUNT, seed=201)\n",
    "\n",
    "# Test MID: (5,6)\n",
    "X_te_MID, y_te_MID, expr_te_MID =\n",
    "    make_depth_stratified_split(Dict(5=>N_MID÷2, 6=>N_MID - (N_MID÷2));\n",
    "                                variable_count=VARIABLE_COUNT, seed=202)\n",
    "\n",
    "# Test OOD: (7,8)\n",
    "X_te_OOD, y_te_OOD, expr_te_OOD =\n",
    "    make_depth_stratified_split(Dict(7=>N_OOD÷2, 8=>N_OOD - (N_OOD÷2));\n",
    "                                variable_count=VARIABLE_COUNT, seed=203)\n",
    "\n",
    "let d = [max_paren_depth(e)+1 for e in expr_te_OOD]\n",
    "    @assert all(x -> x==7 || x==8, d) \"Found non-(7,8) depths in OOD split: $(StatsBase.countmap(d))\"\n",
    "end\n",
    "\n",
    "\n",
    "function max_paren_depth(expr::String)\n",
    "    d = 0; m = 0\n",
    "    @inbounds for c in expr\n",
    "        if c == '('\n",
    "            d += 1; m = max(m, d)\n",
    "        elseif c == ')'\n",
    "            d -= 1\n",
    "        end\n",
    "    end\n",
    "    return m\n",
    "end\n",
    "\n",
    "\n",
    "# 2) Tokenize with assignment, build vocab, pad to fixed length\n",
    "function tokenize_with_assignment(expression::String, variable_row::AbstractVector{<:Integer})\n",
    "    spaced = replace(expression, r\"([()])\" => s\" \\1 \")\n",
    "    raw_tokens = split(strip(spaced))\n",
    "    tokens = String[]\n",
    "    for t in raw_tokens\n",
    "        if startswith(t, \"x\")\n",
    "            idx = parse(Int, t[2:end])\n",
    "            push!(tokens, \"x$(idx)=$(variable_row[idx])\")\n",
    "        elseif t == \"(\" || t == \")\"\n",
    "            continue  # drop parentheses to shorten sequences (consistent with earlier runs)\n",
    "        else\n",
    "            push!(tokens, t)  # \"AND\", \"OR\", \"XOR\", \"NAND\", \"NOT\"\n",
    "        end\n",
    "    end\n",
    "    return tokens\n",
    "end\n",
    "\n",
    "\n",
    "function build_token_sequences(expressions::Vector{String}, X::Array{Int,2})\n",
    "    seqs = Vector{Vector{String}}(undef, length(expressions))\n",
    "    for i in eachindex(expressions)\n",
    "        seqs[i] = tokenize_with_assignment(expressions[i], vec(X[i, :]))\n",
    "    end\n",
    "    return seqs\n",
    "end\n",
    "\n",
    "\n",
    "# Tokenize every split\n",
    "tokens_tr_A  = build_token_sequences(expr_tr_A,  X_tr_A)\n",
    "tokens_tr_B  = build_token_sequences(expr_tr_B,  X_tr_B)\n",
    "tokens_te_ID = build_token_sequences(expr_te_ID, X_te_ID)\n",
    "tokens_te_M  = build_token_sequences(expr_te_MID,X_te_MID)\n",
    "tokens_te_O  = build_token_sequences(expr_te_OOD,X_te_OOD)\n",
    "\n",
    "function build_vocab_with_specials(train_token_sequences::Vector{Vector{String}})\n",
    "    vocab = Dict{String,Int}(\"<PAD>\"=>1, \"<UNK>\"=>2)\n",
    "    next_id = 3\n",
    "    for seq in train_token_sequences\n",
    "        for t in seq\n",
    "            haskey(vocab, t) || (vocab[t] = next_id; next_id += 1)\n",
    "        end\n",
    "    end\n",
    "    return vocab\n",
    "end\n",
    "\n",
    "vocab = build_vocab_with_specials(tokens_tr_A)\n",
    "const PAD_ID = vocab[\"<PAD>\"]\n",
    "const UNK_ID = vocab[\"<UNK>\"]\n",
    "token_to_id(t) = get(vocab, t, UNK_ID)\n",
    "\n",
    "# --- Map tokens -> ids (produces (L, N) matrices) ---\n",
    "function to_ids(tokens::Vector{Vector{String}})\n",
    "    Lmax = maximum(length.(tokens))\n",
    "    n = length(tokens)\n",
    "    Xids = fill(PAD_ID, Lmax, n)\n",
    "    @inbounds for i in 1:n\n",
    "        s = tokens[i]\n",
    "        for j in 1:length(s)\n",
    "            Xids[j, i] = token_to_id(s[j])\n",
    "        end\n",
    "    end\n",
    "    return Xids\n",
    "end\n",
    "\n",
    "Xids_tr_A  = to_ids(tokens_tr_A)\n",
    "Xids_tr_B  = to_ids(tokens_tr_B)\n",
    "Xids_te_ID = to_ids(tokens_te_ID)\n",
    "Xids_te_M  = to_ids(tokens_te_M)\n",
    "Xids_te_O  = to_ids(tokens_te_O)\n",
    "\n",
    "\n",
    "# Compute the maximum sequence length across *all* splits\n",
    "L_A   = size(Xids_tr_A,  1)\n",
    "L_B   = size(Xids_tr_B,  1)\n",
    "L_ID  = size(Xids_te_ID, 1)\n",
    "L_MID = size(Xids_te_M,  1)\n",
    "L_OOD = size(Xids_te_O,  1)\n",
    "\n",
    "# Vocabulary from training only, with <PAD>=1 and <UNK>=2\n",
    "function build_vocab_with_specials(train_token_sequences::Vector{Vector{String}})\n",
    "    vocab = Dict{String,Int}(\"<PAD>\"=>1, \"<UNK>\"=>2)\n",
    "    next_id = 3\n",
    "    for seq in train_token_sequences\n",
    "        for t in seq\n",
    "            haskey(vocab, t) || (vocab[t] = next_id; next_id += 1)\n",
    "        end\n",
    "    end\n",
    "    return vocab\n",
    "end\n",
    "\n",
    "\n",
    "# Vocab ONLY from Phase-A training (guards against leakage)\n",
    "vocab = build_vocab_with_specials(tokens_tr_A)\n",
    "const PAD_ID = vocab[\"<PAD>\"]\n",
    "const UNK_ID = vocab[\"<UNK>\"]\n",
    "token_to_id(t) = get(vocab, t, UNK_ID)\n",
    "\n",
    "\n",
    "# Per-split padding (no global max)\n",
    "function to_ids(tokens::Vector{Vector{String}})\n",
    "    Lmax = maximum(length.(tokens))\n",
    "    n = length(tokens)\n",
    "    Xids = fill(PAD_ID, Lmax, n)\n",
    "    @inbounds for i in 1:n\n",
    "        s = tokens[i]\n",
    "        for j in 1:length(s)\n",
    "            Xids[j, i] = token_to_id(s[j])\n",
    "        end\n",
    "    end\n",
    "    return Xids\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "depths(v) = [max_paren_depth(e)+1 for e in v]\n",
    "\n",
    "@show StatsBase.countmap(depths(expr_tr_A))\n",
    "@show StatsBase.countmap(depths(expr_tr_B))\n",
    "@show StatsBase.countmap(depths(expr_te_ID))\n",
    "@show StatsBase.countmap(depths(expr_te_MID))\n",
    "@show StatsBase.countmap(depths(expr_te_OOD))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# +1 if you use CLS (the CLS token is prepended to H_in)\n",
    "POS_L_MAX = max(L_A, L_B, L_ID, L_MID, L_OOD) + 1\n",
    "\n",
    "models = HRMFlux.build_models(cfg; positional_encoding_kind=:sinusoidal, pos_L_max=POS_L_MAX)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function seq_lengths_from_pad_id(Xids::AbstractMatrix{<:Integer}, pad_id::Int)\n",
    "    L, B = size(Xids)\n",
    "    lengths = fill(L, B)\n",
    "    @inbounds for b in 1:B\n",
    "        for t in 1:L\n",
    "            if Xids[t, b] == pad_id\n",
    "                lengths[b] = t - 1\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return lengths\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# keep PAD embedding at zero to avoid length bias\n",
    "if models.tok_emb !== nothing\n",
    "    models.tok_emb.weight[:, PAD_ID] .= 0f0\n",
    "end\n",
    "\n",
    "\n",
    "function each_minibatch_bucketed(X::AbstractMatrix{<:Integer}, y::AbstractVector{<:Integer};\n",
    "                                 batch::Int, buckets::Int=6, pad_id::Int=PAD_ID)\n",
    "    L, N = size(X)\n",
    "    lens = fill(L, N)\n",
    "    @inbounds for i in 1:N, t in 1:L\n",
    "        if X[t,i] == pad_id\n",
    "            lens[i] = t-1\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    order  = sortperm(1:N, by=i->lens[i])\n",
    "    groups = Iterators.partition(order, max(1, ceil(Int, N/buckets)))\n",
    "    out = Vector{Tuple{Matrix{Int}, Vector{Int}}}()\n",
    "    for g in groups\n",
    "        idx = collect(g); Random.shuffle!(idx)\n",
    "        for k in 1:batch:length(idx)\n",
    "            sel = idx[k:min(k+batch-1, length(idx))]\n",
    "            push!(out, (X[:, sel], y[sel]))\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "function each_minibatch(X::AbstractMatrix{<:Integer}, y::AbstractVector{<:Integer}, batch_size::Int)\n",
    "    idx = collect(1:size(X, 2))\n",
    "    Random.shuffle!(idx)\n",
    "    out = Vector{Tuple{Matrix{Int}, Vector{Int}}}()\n",
    "    for k in 1:batch_size:length(idx)\n",
    "        sel = idx[k:min(k+batch_size-1, length(idx))]\n",
    "        push!(out, (X[:, sel], y[sel]))\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "\"Yield a mixed stream of mini-batches from A and B with probability pB for B.\"\n",
    "function each_minibatch_mixed(XA::AbstractMatrix{<:Integer}, yA::AbstractVector{<:Integer},\n",
    "                              XB::AbstractMatrix{<:Integer}, yB::AbstractVector{<:Integer};\n",
    "                              batch::Int, pB::Float64, buckets::Int=6, pad_id::Int=PAD_ID)\n",
    "\n",
    "    itA = each_minibatch_bucketed(XA, yA; batch=batch, buckets=buckets, pad_id=pad_id)\n",
    "    itB = each_minibatch_bucketed(XB, yB; batch=batch, buckets=buckets, pad_id=pad_id)\n",
    "\n",
    "    ia = 1; ib = 1\n",
    "    out = Vector{Tuple{Matrix{Int}, Vector{Int}}}()\n",
    "    while ia <= length(itA) || ib <= length(itB)\n",
    "        useB = rand() < pB\n",
    "        if useB && ib <= length(itB)\n",
    "            push!(out, itB[ib]); ib += 1\n",
    "        elseif ia <= length(itA)\n",
    "            push!(out, itA[ia]); ia += 1\n",
    "        elseif ib <= length(itB)\n",
    "            push!(out, itB[ib]); ib += 1\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function batch_loss(models, x_batch::AbstractMatrix{<:Integer}, y_batch::AbstractVector{<:Integer}, cfg)\n",
    "    batch_size = size(x_batch, 2)\n",
    "    low_state, high_state = HRMFlux.init_states(batch_size, cfg.d_hid)\n",
    "    \n",
    "    # yhat, _, _ = HRMFlux.run_segment_GRU!(models, x_batch, low_state, high_state; N=cfg.N, T=cfg.T, cfg=cfg)\n",
    "    yhat, _, _ = HRMFlux.run_sequence_segment!(models, x_batch, low_state, high_state; N=cfg.N, cfg=cfg)\n",
    "\n",
    "    targets = reshape(Float32.(y_batch), 1, batch_size)\n",
    "    return Flux.logitbinarycrossentropy(yhat, targets)\n",
    "end\n",
    "\n",
    "\n",
    "# function accuracy(models, X::AbstractMatrix{<:Integer}, y::AbstractVector{<:Integer}, cfg; batch_size::Int=256)\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for (xb, yb) in each_minibatch(X, y, batch_size)\n",
    "#         bs = size(xb, 2)\n",
    "#         low_state, high_state = HRMFlux.init_states(bs, cfg.d_hid)\n",
    "#         yhat, _, _ = HRMFlux.run_sequence_segment!(models, xb, low_state, high_state; N=cfg.N, cfg=cfg)\n",
    "#         preds = @. yhat > 0\n",
    "#         correct += sum(Int.(preds[1, :]) .== yb)\n",
    "#         total   += bs\n",
    "#     end\n",
    "#     return correct / total\n",
    "# end\n",
    "\n",
    "\n",
    "function accuracy(models, X::AbstractMatrix{<:Integer}, y::AbstractVector{<:Integer}, cfg; batch_size::Int=256)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # use the function arguments X, y — not Xtr, ytr\n",
    "    for (xb, yb) in each_minibatch_bucketed(X, y; batch=min(cfg.batch, batch_size), buckets=6)\n",
    "        bs = size(xb, 2)\n",
    "        low_state, high_state = HRMFlux.init_states(bs, cfg.d_hid)\n",
    "\n",
    "        yhat, _, _ = HRMFlux.run_sequence_segment!(models, xb, low_state, high_state; N=cfg.N, cfg=cfg)\n",
    "        preds = @. yhat > 0\n",
    "        correct += sum(Int.(preds[1, :]) .== yb)\n",
    "        total   += bs\n",
    "    end\n",
    "    return correct / total\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function accuracy_by_depth(models, Xids, y, exprs; cfg, batch_size=256)\n",
    "    de = [max_paren_depth(e) + 1 for e in exprs]  # structural depth\n",
    "    mp = Dict{Int, Vector{Int}}()\n",
    "    for (i,d) in enumerate(de)\n",
    "        push!(get!(mp, d, Int[]), i)\n",
    "    end\n",
    "    out = Dict{Int,Float64}()\n",
    "    for (d, idx) in sort(collect(mp); by=first)\n",
    "        out[d] = accuracy(models, Xids[:, idx], y[idx], cfg; batch_size=batch_size)\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "@assert size(X_tr_A,2) == VARIABLE_COUNT\n",
    "@assert length(y_tr_A) == size(X_tr_A,1) == length(expr_tr_A)\n",
    "@assert length(y_tr_B) == size(X_tr_B,1) == length(expr_tr_B)\n",
    "@assert length(y_te_ID)  == size(X_te_ID,1)  == length(expr_te_ID)\n",
    "@assert length(y_te_MID) == size(X_te_MID,1) == length(expr_te_MID)\n",
    "@assert length(y_te_OOD) == size(X_te_OOD,1) == length(expr_te_OOD)\n",
    "\n",
    "@assert size(Xids_tr_A,2) == size(X_tr_A,1)\n",
    "@assert size(Xids_te_O, 2) == size(X_te_OOD,1)\n",
    "\n",
    "\n",
    "\n",
    "# 5) Train and evaluate\n",
    "# curriculum phases\n",
    "epochs_A = 10    # Phase A (2-4)\n",
    "epochs_B = 10    # Phase B (2-6)\n",
    "total_epochs = epochs_A + epochs_B\n",
    "\n",
    "# opt_state = Optimisers.setup(Optimisers.Adam(cfg.lr), models)\n",
    "base_lr = cfg.lr\n",
    "opt = Optimisers.Adam(base_lr)\n",
    "opt_state = Optimisers.setup(opt, models)\n",
    "\n",
    "\n",
    "for epoch in 1:total_epochs\n",
    "    total_loss = 0.0; batches = 0\n",
    "\n",
    "    # mixing schedule: 0.0 during Phase A, then ramp A→B across Phase B\n",
    "    pB = epoch <= epochs_A ? 0.0 : (epoch - epochs_A) / epochs_B\n",
    "    pB = clamp(pB, 0.3, 1.0)  # keep at least some B once Phase B starts\n",
    "\n",
    "    \n",
    "\n",
    "    for (xb, yb) in each_minibatch_mixed(Xids_tr_A, y_tr_A, Xids_tr_B, y_tr_B;\n",
    "                                        batch=cfg.batch, pB=pB, buckets=6, pad_id=PAD_ID)\n",
    "\n",
    "        # keep PAD column neutral (before & after update)\n",
    "        if hasproperty(models, :tok_emb) && models.tok_emb !== nothing\n",
    "            models.tok_emb.weight[:, PAD_ID] .= 0f0\n",
    "        end\n",
    "\n",
    "        L, back = Zygote.pullback(m -> batch_loss(m, xb, yb, cfg), models)\n",
    "        grads = back(one(L))[1]\n",
    "        opt_state, models = Optimisers.update(opt_state, models, grads)\n",
    "\n",
    "        if hasproperty(models, :tok_emb) && models.tok_emb !== nothing\n",
    "            models.tok_emb.weight[:, PAD_ID] .= 0f0\n",
    "        end\n",
    "\n",
    "        total_loss += Float64(L); batches += 1\n",
    "    end\n",
    "\n",
    "    acc_id  = accuracy(models, Xids_te_ID,  y_te_ID,  cfg)   # 2-4\n",
    "    acc_mid = accuracy(models, Xids_te_M,   y_te_MID, cfg)   # 5-6\n",
    "    acc_ood = accuracy(models, Xids_te_O,   y_te_OOD, cfg)   # 7-8\n",
    "    @info \"epoch=$(epoch)  loss=$(round(total_loss/batches, digits=4))  \" *\n",
    "          \"ID(2-4)=$(round(acc_id,digits=3))  MID(5-6)=$(round(acc_mid,digits=3))  OOD(7-8)=$(round(acc_ood,digits=3))\"\n",
    "\n",
    "    ood = accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg=cfg)\n",
    "    acc7 = get(ood, 7, NaN); acc8 = get(ood, 8, NaN)\n",
    "    ood_macro = (acc7 + acc8) / 2\n",
    "    @info \"OOD macro (7/8 equally) = $(round(ood_macro, digits=3))\"\n",
    "\n",
    "    if epoch % 5 == 0\n",
    "        @show accuracy_by_depth(models, Xids_te_O,  y_te_OOD,  expr_te_OOD;  cfg=cfg)\n",
    "        @show accuracy_by_depth(models, Xids_te_M,  y_te_MID,  expr_te_MID;  cfg=cfg)\n",
    "        println(\"Final depth bins (OOD 7-8):\")\n",
    "        @show accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg=cfg)\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Final depth bins (OOD 7-8):\")\n",
    "@show accuracy_by_depth(models, Xids_te_O, y_te_OOD, expr_te_OOD; cfg=cfg)\n",
    "\n",
    "println(\"Final depth bins (MID 5-6):\")\n",
    "@show accuracy_by_depth(models, Xids_te_M, y_te_MID, expr_te_MID; cfg=cfg)\n",
    "\n",
    "println(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9388947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_ID = Dict(4 => 334, 2 => 333, 3 => 333)\n",
      "post_MID = Dict(5 => 500, 6 => 500)\n",
      "post_OOD = Dict(7 => 500, 8 => 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Int64} with 2 entries:\n",
       "  7 => 500\n",
       "  8 => 500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "post_ID  = countmap([max_paren_depth(e)+1 for e in expr_te_ID])\n",
    "post_MID = countmap([max_paren_depth(e)+1 for e in expr_te_MID])\n",
    "post_OOD = countmap([max_paren_depth(e)+1 for e in expr_te_OOD])\n",
    "\n",
    "@show post_ID\n",
    "@show post_MID\n",
    "@show post_OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "556169d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countmap(depths(expr_te_OOD)) = Dict(7 => 500, 8 => 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: import of StatsBase.countmap into Main conflicts with an existing identifier; ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Int64} with 2 entries:\n",
       "  7 => 500\n",
       "  8 => 500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_paren_depth(s) = (d=0;m=0; for c in s; c=='(' && (d+=1; m=max(m,d)); c==')' && (d-=1); end; m)\n",
    "depths(v) = [max_paren_depth(e)+1 for e in v]\n",
    "using StatsBase: countmap\n",
    "@show countmap(depths(expr_te_OOD))  # expect Dict(7=>…, 8=>…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce118198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f95c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abec2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a31fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008ac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29415f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c19ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b870c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6e437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.9",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
