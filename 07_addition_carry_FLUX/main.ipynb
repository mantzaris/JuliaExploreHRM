{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136dfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8168a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/repos/JuliaExploreHRM`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")  #one level up, where Project.toml lives\n",
    "Pkg.instantiate()   #download/install anything missing\n",
    "# Pkg.status();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c850bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "using Random, Statistics\n",
    "using Flux\n",
    "using Flux, Zygote, Optimisers\n",
    "using Flux: onehotbatch, onecold\n",
    "using DataFrames, Plots, CSV\n",
    "using Test\n",
    "using CSV, DataFrames\n",
    "using Measures\n",
    "\n",
    "using NNlib: gelu\n",
    "using PositionalEmbeddings     # Absolute positional encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdc4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"..\", \"data\", \"long_addition_carries_gen.jl\"))\n",
    "using .AdditionCarryData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae3fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"..\", \"data\", \"hrm_common_addition_FLUX.jl\"))\n",
    "using .HRMFluxAddCarry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49ea9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d8a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure length shift like your Dyck/Boolean splits (2-4 -> 5 -> 6-7)\n",
    "splits = AdditionCarryData.make_addition_sum_splits(\n",
    "    n_train=100_000, n_val=10_000, n_test_id=10_000, n_test_mid=10_000, n_test_ood=10_000,\n",
    "    train_digits_a=2:4, train_digits_b=2:4,\n",
    "    mid_digits_a=5:5,   mid_digits_b=5:5,\n",
    "    ood_digits_a=6:7,   ood_digits_b=6:7,\n",
    "    base=10, lsd_first=true, seed=1234,\n",
    "    require_carry=nothing,     # leave unconstrained\n",
    "    min_carry_chain_id=0,      # ID\n",
    "    min_carry_chain_mid=0,     # MID\n",
    "    min_carry_chain_ood=0      # OOD\n",
    ")\n",
    "\n",
    "AdditionCarryData.write_addition_sum_splits(\"datasets/addition_sum\", splits; base=10, include_vocab=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fb76b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780e4fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27799eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_verification_splits"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    make_verification_splits(; kwargs...) -> NamedTuple\n",
    "\n",
    "Builds five splits for addition-with-carry verification (binary labels):\n",
    "  - train_A: shorter regime (analogue of your Phase-A)\n",
    "  - train_B: longer regime  (analogue of your Phase-B)\n",
    "  - val_id  : ID validation   (same regime as A)\n",
    "  - test_mid: slightly longer\n",
    "  - test_ood: much longer\n",
    "\"\"\"\n",
    "function make_verification_splits(;  # sizes\n",
    "    n_train_A::Int = 100_000,\n",
    "    n_train_B::Int = 100_000,\n",
    "    n_val::Int     = 10_000,\n",
    "    n_test_mid::Int= 10_000,\n",
    "    n_test_ood::Int= 10_000,\n",
    "\n",
    "    # length regimes for A and B operands (MSD lengths)\n",
    "    trainA_digits_a::UnitRange{Int} = 2:4,\n",
    "    trainA_digits_b::UnitRange{Int} = 2:4,\n",
    "    trainB_digits_a::UnitRange{Int} = 2:6,\n",
    "    trainB_digits_b::UnitRange{Int} = 2:6,\n",
    "    mid_digits_a::UnitRange{Int}    = 5:5,\n",
    "    mid_digits_b::UnitRange{Int}    = 5:5,\n",
    "    ood_digits_a::UnitRange{Int}    = 6:7,\n",
    "    ood_digits_b::UnitRange{Int}    = 6:7,\n",
    "\n",
    "    # formatting and arithmetic knobs\n",
    "    base::Int = 10,\n",
    "    lsd_first::Bool = true,\n",
    "    allow_leading_zero::Bool = false,\n",
    "    delimiter::String = \" \",\n",
    "    include_plus::Bool = true,\n",
    "    include_equals::Bool = true,\n",
    "\n",
    "    # carry constraints (optional)\n",
    "    require_carry::Union{Bool,Nothing} = nothing,\n",
    "    min_carry_chain_A::Int  = 0,\n",
    "    min_carry_chain_B::Int  = 0,\n",
    "    min_carry_chain_mid::Int= 0,\n",
    "    min_carry_chain_ood::Int= 0,\n",
    "\n",
    "    # class balance (true equations vs false)\n",
    "    positive_fraction::Float64 = 0.5,\n",
    "\n",
    "    # reproducibility\n",
    "    seed::Int = 1234\n",
    ")\n",
    "    gen = AdditionCarryData.generate_addition_verification_dataset\n",
    "\n",
    "    train_A = gen(n_train_A;\n",
    "        digits_a=trainA_digits_a, digits_b=trainA_digits_b, base=base,\n",
    "        positive_fraction=positive_fraction, random_seed=seed,\n",
    "        lsd_first=lsd_first, allow_leading_zero=allow_leading_zero,\n",
    "        require_carry=require_carry, min_carry_chain=min_carry_chain_A,\n",
    "        delimiter=delimiter, include_plus=include_plus, include_equals=include_equals)\n",
    "\n",
    "    train_B = gen(n_train_B;\n",
    "        digits_a=trainB_digits_a, digits_b=trainB_digits_b, base=base,\n",
    "        positive_fraction=positive_fraction, random_seed=seed+1,\n",
    "        lsd_first=lsd_first, allow_leading_zero=allow_leading_zero,\n",
    "        require_carry=require_carry, min_carry_chain=min_carry_chain_B,\n",
    "        delimiter=delimiter, include_plus=include_plus, include_equals=include_equals)\n",
    "\n",
    "    val_id = gen(n_val;\n",
    "        digits_a=trainA_digits_a, digits_b=trainA_digits_b, base=base,\n",
    "        positive_fraction=positive_fraction, random_seed=seed+2,\n",
    "        lsd_first=lsd_first, allow_leading_zero=allow_leading_zero,\n",
    "        require_carry=require_carry, min_carry_chain=min_carry_chain_A,\n",
    "        delimiter=delimiter, include_plus=include_plus, include_equals=include_equals)\n",
    "\n",
    "    test_mid = gen(n_test_mid;\n",
    "        digits_a=mid_digits_a, digits_b=mid_digits_b, base=base,\n",
    "        positive_fraction=positive_fraction, random_seed=seed+3,\n",
    "        lsd_first=lsd_first, allow_leading_zero=allow_leading_zero,\n",
    "        require_carry=require_carry, min_carry_chain=min_carry_chain_mid,\n",
    "        delimiter=delimiter, include_plus=include_plus, include_equals=include_equals)\n",
    "\n",
    "    test_ood = gen(n_test_ood;\n",
    "        digits_a=ood_digits_a, digits_b=ood_digits_b, base=base,\n",
    "        positive_fraction=positive_fraction, random_seed=seed+4,\n",
    "        lsd_first=lsd_first, allow_leading_zero=allow_leading_zero,\n",
    "        require_carry=require_carry, min_carry_chain=min_carry_chain_ood,\n",
    "        delimiter=delimiter, include_plus=include_plus, include_equals=include_equals)\n",
    "\n",
    "    # Convert to (strings, labels::Int)\n",
    "    to_xy(ds) = begin\n",
    "        xs = [r.input for r in ds]\n",
    "        ys = [r.label ? 1 : 0 for r in ds]\n",
    "        xs, ys\n",
    "    end\n",
    "\n",
    "    x_tr_A,  y_tr_A  = to_xy(train_A)\n",
    "    x_tr_B,  y_tr_B  = to_xy(train_B)\n",
    "    x_val,   y_val   = to_xy(val_id)\n",
    "    x_mid,   y_mid   = to_xy(test_mid)\n",
    "    x_ood,   y_ood   = to_xy(test_ood)\n",
    "\n",
    "    return (trainA_x=x_tr_A, trainA_y=y_tr_A,\n",
    "            trainB_x=x_tr_B, trainB_y=y_tr_B,\n",
    "            val_x=x_val, val_y=y_val,\n",
    "            mid_x=x_mid, mid_y=y_mid,\n",
    "            ood_x=x_ood, ood_y=y_ood)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ac2629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_tokenize_pad"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"Digits 0..(base-1), then '+', '=', and '<pad>'.\"\n",
    "build_vocab_with_pad(base::Int) =\n",
    "    AdditionCarryData.build_vocabulary(base; include_plus=true, include_equals=true,\n",
    "                                       include_pad=true, include_eos=false)\n",
    "\n",
    "\"\"\"\n",
    "batch_tokenize_pad(strings, vocab; pad_id) -> (L_max, B) Int matrix.\n",
    "Whitespace-split, map with `vocab`, then right-pad with `pad_id`.\n",
    "\"\"\"\n",
    "function batch_tokenize_pad(strings::Vector{String},\n",
    "                            vocab::Dict{String,Int};\n",
    "                            pad_id::Int)\n",
    "    B = length(strings)\n",
    "    token_lists = Vector{Vector{Int}}(undef, B)\n",
    "    Lmax = 0\n",
    "    @inbounds for i in 1:B\n",
    "        ids = AdditionCarryData.tokenize_with_vocabulary(strings[i], vocab)\n",
    "        token_lists[i] = ids\n",
    "        Lmax = max(Lmax, length(ids))\n",
    "    end\n",
    "    X = fill(pad_id, Lmax, B)\n",
    "    @inbounds for i in 1:B\n",
    "        ids = token_lists[i]\n",
    "        if !isempty(ids)\n",
    "            X[1:length(ids), i] = ids\n",
    "        end\n",
    "    end\n",
    "    X\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142c0e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128-element view(::Matrix{Float32}, :, 13) with eltype Float32:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Splits ----\n",
    "splits = make_verification_splits(\n",
    "    n_train_A=100_000, n_train_B=100_000,\n",
    "    n_val=10_000, n_test_mid=10_000, n_test_ood=10_000,\n",
    "    trainA_digits_a=2:4, trainA_digits_b=2:4,\n",
    "    trainB_digits_a=2:6, trainB_digits_b=2:6,\n",
    "    mid_digits_a=5:5, mid_digits_b=5:5,\n",
    "    ood_digits_a=6:7, ood_digits_b=6:7,\n",
    "    base=10, lsd_first=true, seed=1234,\n",
    "    require_carry=nothing,\n",
    "    min_carry_chain_A=0, min_carry_chain_B=0,\n",
    "    min_carry_chain_mid=0, min_carry_chain_ood=0,\n",
    "    positive_fraction=0.5\n",
    ")\n",
    "\n",
    "# Assign in variables that mirror the workflow\n",
    "x_tr_A,  y_tr_A  = splits.trainA_x, splits.trainA_y\n",
    "x_tr_B,  y_tr_B  = splits.trainB_x, splits.trainB_y\n",
    "x_te_ID, y_te_ID = splits.val_x,    splits.val_y   # ID validation\n",
    "x_te_M,  y_te_M  = splits.mid_x,    splits.mid_y   # MID\n",
    "x_te_O,  y_te_O  = splits.ood_x,    splits.ood_y   # OOD\n",
    "\n",
    "# Keep references for any reports you may add later\n",
    "xs_ID, xs_MID, xs_OOD = x_te_ID, x_te_M, x_te_O\n",
    "\n",
    "# ---- Vocabulary and tokenization ----\n",
    "vocab  = build_vocab_with_pad(10)\n",
    "pad_id = vocab[\"<pad>\"]\n",
    "\n",
    "to_ids(xs::Vector{String}) = batch_tokenize_pad(xs, vocab; pad_id=pad_id)\n",
    "\n",
    "Xids_tr_A  = to_ids(x_tr_A)\n",
    "Xids_tr_B  = to_ids(x_tr_B)\n",
    "Xids_te_ID = to_ids(x_te_ID)\n",
    "Xids_te_M  = to_ids(x_te_M)\n",
    "Xids_te_O  = to_ids(x_te_O)\n",
    "\n",
    "# ---- Positional bound (add 1 for CLS in H blocks) ----\n",
    "POS_L_MAX = maximum((size(Xids_tr_A,1), size(Xids_tr_B,1),\n",
    "                     size(Xids_te_ID,1), size(Xids_te_M,1), size(Xids_te_O,1))) + 1\n",
    "\n",
    "# ---- HRM config (binary verification: single logit) ----\n",
    "cfg = (\n",
    "    d_in   = 0,            # unused in token path\n",
    "    d_hid  = 96,\n",
    "    d_out  = 1,            # single logit (use σ + BCE)\n",
    "    N      = 3,            # outer HRM cycles\n",
    "    T      = POS_L_MAX,    # PE bound\n",
    "    batch  = 32,\n",
    "    lr     = 5e-5,\n",
    "    num_tokens = length(vocab),   # 10 digits + '+' + '=' + '<pad>' = 13\n",
    "    d_embed    = 128,\n",
    "    l_heads    = 4,  l_ff_mult = 6,\n",
    "    h_heads    = 4,  h_ff_mult = 6,\n",
    "    dropout    = 0.1,\n",
    "    pad_id     = pad_id\n",
    ")\n",
    "\n",
    "# ---- Build both architectures ----\n",
    "models_HL = HRMFluxAddCarry.build_models_addcarry(cfg;\n",
    "    arch = :HL,\n",
    "    l_positional_encoding_kind = :none,\n",
    "    h_positional_encoding_kind = :sinusoidal,\n",
    "    pos_L_max = POS_L_MAX\n",
    ")\n",
    "\n",
    "models_HH = HRMFluxAddCarry.build_models_addcarry(cfg;\n",
    "    arch = :HH,\n",
    "    l_positional_encoding_kind = :sinusoidal,\n",
    "    h_positional_encoding_kind = :sinusoidal,\n",
    "    pos_L_max = POS_L_MAX\n",
    ")\n",
    "\n",
    "# ---- Keep PAD embedding neutral to avoid length bias ----\n",
    "function freeze_pad!(models, pad_id::Int)\n",
    "    if hasproperty(models, :tok_emb) && models.tok_emb !== nothing\n",
    "        models.tok_emb.weight[:, pad_id] .= 0f0\n",
    "    end\n",
    "end\n",
    "freeze_pad!(models_HL, pad_id)\n",
    "freeze_pad!(models_HH, pad_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a418e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_matrix (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length-bucketed minibatches (by effective non-pad length)\n",
    "function each_minibatch_bucketed(X::AbstractMatrix{<:Integer}, y::AbstractVector{<:Integer};\n",
    "                                 batch::Int, buckets::Int=6, pad_id::Int,\n",
    "                                 rng::AbstractRNG=Random.GLOBAL_RNG)\n",
    "    L, N = size(X)\n",
    "    lens = fill(L, N)\n",
    "    @inbounds for i in 1:N, t in 1:L\n",
    "        if X[t, i] == pad_id\n",
    "            lens[i] = t - 1\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    order  = sortperm(1:N, by=i->lens[i])\n",
    "    groups = Iterators.partition(order, max(1, ceil(Int, N/buckets)))\n",
    "    out = Vector{Tuple{Matrix{Int}, Vector{Int}}}()\n",
    "    for g in groups\n",
    "        idx = collect(g); Random.shuffle!(rng, idx)\n",
    "        for k in 1:batch:length(idx)\n",
    "            sel = idx[k:min(k+batch-1, length(idx))]\n",
    "            push!(out, (X[:, sel], y[sel]))\n",
    "        end\n",
    "    end\n",
    "    out\n",
    "end\n",
    "\n",
    "# Mixed A/B stream with cosine schedule (for curriculum)\n",
    "function each_minibatch_mixed(XA, yA, XB, yB; batch::Int, pB::Float64, buckets::Int,\n",
    "                              pad_id::Int, rng::AbstractRNG=Random.GLOBAL_RNG)\n",
    "    itA = each_minibatch_bucketed(XA, yA; batch=batch, buckets=buckets, pad_id=pad_id, rng=rng)\n",
    "    itB = each_minibatch_bucketed(XB, yB; batch=batch, buckets=buckets, pad_id=pad_id, rng=rng)\n",
    "    ia = 1; ib = 1\n",
    "    out = Vector{Tuple{Matrix{Int}, Vector{Int}}}()\n",
    "    while ia <= length(itA) || ib <= length(itB)\n",
    "        useB = rand(rng) < pB\n",
    "        if useB && ib <= length(itB)\n",
    "            push!(out, itB[ib]); ib += 1\n",
    "        elseif ia <= length(itA)\n",
    "            push!(out, itA[ia]); ia += 1\n",
    "        elseif ib <= length(itB)\n",
    "            push!(out, itB[ib]); ib += 1\n",
    "        end\n",
    "    end\n",
    "    out\n",
    "end\n",
    "\n",
    "# Loss and metrics (single-logit BCE)\n",
    "logit_bce(ŷ, y::Vector{Int}) = Flux.Losses.logitbinarycrossentropy(vec(ŷ), Float32.(y))\n",
    "accuracy(ŷ, y::Vector{Int})  = mean((σ.(vec(ŷ)) .>= 0.5) .== (y .== 1))\n",
    "\n",
    "# Batch loss wrapper using your HRM runner\n",
    "function batch_loss(models, x_batch::AbstractMatrix{<:Integer}, y_batch::AbstractVector{<:Integer}, cfg)\n",
    "    B = size(x_batch, 2)\n",
    "    low_state, high_state = HRMFluxAddCarry.init_states(B, cfg.d_hid)\n",
    "    ŷ, _, _ = HRMFluxAddCarry.run_sequence_addcarry!(models, x_batch, low_state, high_state; N=cfg.N, cfg=cfg)\n",
    "    logit_bce(ŷ, y_batch)\n",
    "end\n",
    "\n",
    "# Batched accuracy evaluation\n",
    "function evaluate_matrix(models, X::AbstractMatrix{<:Integer}, y::Vector{Int}, cfg; batch_size::Int=256)\n",
    "    total_acc, total_n = 0.0, 0\n",
    "    N = size(X, 2)\n",
    "    for k in 1:batch_size:N\n",
    "        sel = k:min(k+batch_size-1, N)\n",
    "        xb = X[:, sel]; yb = y[sel]\n",
    "        B  = size(xb, 2)\n",
    "        low_state, high_state = HRMFluxAddCarry.init_states(B, cfg.d_hid)\n",
    "        ŷ, _, _ = HRMFluxAddCarry.run_sequence_addcarry!(models, xb, low_state, high_state; N=cfg.N, cfg=cfg)\n",
    "        total_acc += mean((σ.(vec(ŷ)) .>= 0.5) .== (yb .== 1)) * B\n",
    "        total_n   += B\n",
    "    end\n",
    "    total_acc / total_n\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df17044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: H+L epoch 1  loss 0.0283  ID 0.5  MID 0.5  OOD 0.5\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/07_addition_carry_FLUX/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:69\n",
      "┌ Info: H+L epoch 2  loss 0.0345  ID 0.5  MID 0.5  OOD 0.5\n",
      "└ @ Main /home/resort/Documents/repos/JuliaExploreHRM/07_addition_carry_FLUX/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:69\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      "  [1] Array\n",
      "    @ ./boot.jl:489 [inlined]\n",
      "  [2] Array\n",
      "    @ ./boot.jl:494 [inlined]\n",
      "  [3] similar\n",
      "    @ ./abstractarray.jl:876 [inlined]\n",
      "  [4] similar\n",
      "    @ ./abstractarray.jl:875 [inlined]\n",
      "  [5] similar\n",
      "    @ ./broadcast.jl:224 [inlined]\n",
      "  [6] similar\n",
      "    @ ./broadcast.jl:223 [inlined]\n",
      "  [7] copy\n",
      "    @ ./broadcast.jl:928 [inlined]\n",
      "  [8] materialize\n",
      "    @ ./broadcast.jl:903 [inlined]\n",
      "  [9] broadcast_preserving_zero_d\n",
      "    @ ./broadcast.jl:892 [inlined]\n",
      " [10] /(A::Array{Float32, 4}, B::Float32)\n",
      "    @ Base ./arraymath.jl:24\n",
      " [11] rrule\n",
      "    @ ~/.julia/packages/ChainRules/166sf/src/rulesets/Base/arraymath.jl:402 [inlined]\n",
      " [12] rrule\n",
      "    @ ~/.julia/packages/ChainRulesCore/Vsbj9/src/rules.jl:138 [inlined]\n",
      " [13] chain_rrule\n",
      "    @ ~/.julia/packages/Zygote/55SqB/src/compiler/chainrules.jl:234 [inlined]\n",
      " [14] macro expansion\n",
      "    @ ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0 [inlined]\n",
      " [15] _pullback\n",
      "    @ ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:81 [inlined]\n",
      " [16] adjoint\n",
      "    @ ~/.julia/packages/Zygote/55SqB/src/lib/broadcast.jl:104 [inlined]\n",
      " [17] _pullback\n",
      "    @ ~/.julia/packages/ZygoteRules/CkVIK/src/adjoint.jl:67 [inlined]\n",
      " [18] #dot_product_attention_scores#167\n",
      "    @ ~/.julia/packages/NNlib/1TYHL/src/attention.jl:118 [inlined]\n",
      " [19] _pullback(::Zygote.Context{false}, ::NNlib.var\"##dot_product_attention_scores#167\", ::Dropout{Float64, Colon, TaskLocalRNG}, ::Nothing, ::typeof(dot_product_attention_scores), ::Array{Float32, 4}, ::Array{Float32, 4}, ::Nothing)\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [20] dot_product_attention_scores\n",
      "    @ ~/.julia/packages/NNlib/1TYHL/src/attention.jl:112 [inlined]\n",
      " [21] _pullback(::Zygote.Context{false}, ::typeof(Core.kwcall), ::@NamedTuple{fdrop::Dropout{Float64, Colon, TaskLocalRNG}, mask::Nothing}, ::typeof(dot_product_attention_scores), ::Array{Float32, 4}, ::Array{Float32, 4}, ::Nothing)\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [22] _dot_product_attention\n",
      "    @ ~/.julia/packages/NNlib/1TYHL/src/attention.jl:91 [inlined]\n",
      " [23] _pullback(::Zygote.Context{false}, ::typeof(NNlib._dot_product_attention), ::Array{Float32, 4}, ::Array{Float32, 4}, ::Array{Float32, 4}, ::Nothing, ::Dropout{Float64, Colon, TaskLocalRNG}, ::Nothing)\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [24] #dot_product_attention#166\n",
      "    @ ~/.julia/packages/NNlib/1TYHL/src/attention.jl:82 [inlined]\n",
      " [25] _pullback(::Zygote.Context{false}, ::NNlib.var\"##dot_product_attention#166\", ::Dropout{Float64, Colon, TaskLocalRNG}, ::Nothing, ::Int64, ::typeof(dot_product_attention), ::Array{Float32, 3}, ::Array{Float32, 3}, ::Array{Float32, 3}, ::Nothing)\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [26] dot_product_attention\n",
      "    @ ~/.julia/packages/NNlib/1TYHL/src/attention.jl:52 [inlined]\n",
      " [27] _pullback(::Zygote.Context{false}, ::typeof(Core.kwcall), ::@NamedTuple{nheads::Int64, mask::Nothing, fdrop::Dropout{Float64, Colon, TaskLocalRNG}}, ::typeof(dot_product_attention), ::Array{Float32, 3}, ::Array{Float32, 3}, ::Array{Float32, 3}, ::Nothing)\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [28] #_#302\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/attention.jl:128 [inlined]\n",
      " [29] _pullback(::Zygote.Context{false}, ::Flux.var\"##_#302\", ::Nothing, ::MultiHeadAttention{Dense{typeof(identity), Matrix{Float32}, Bool}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}, ::Array{Float32, 3}, ::Array{Float32, 3}, ::Array{Float32, 3}, ::Nothing)\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [30] MultiHeadAttention\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/attention.jl:120 [inlined]\n",
      "--- the last 2 lines are repeated 1 more time ---\n",
      " [33] _pullback(::Zygote.Context{false}, ::MultiHeadAttention{Dense{typeof(identity), Matrix{Float32}, Bool}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}, ::Array{Float32, 3}, ::Array{Float32, 3}, ::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [34] MultiHeadAttention\n",
      "    @ ~/.julia/packages/Flux/uRn8o/src/layers/attention.jl:115 [inlined]\n",
      " [35] _pullback(ctx::Zygote.Context{false}, f::MultiHeadAttention{Dense{typeof(identity), Matrix{Float32}, Bool}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}, args::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [36] #forward_block#2\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_addition_FLUX.jl:101 [inlined]\n",
      " [37] _pullback(::Zygote.Context{false}, ::Main.HRMFluxAddCarry.var\"##forward_block#2\", ::Nothing, ::typeof(forward_block), ::TransformerBlock{Nothing}, ::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [38] forward_block\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_addition_FLUX.jl:76 [inlined]\n",
      " [39] _pullback(::Zygote.Context{false}, ::typeof(forward_block), ::TransformerBlock{Nothing}, ::Array{Float32, 3})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [40] #_run_sequence_HL!#5\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_addition_FLUX.jl:284 [inlined]\n",
      " [41] _pullback(::Zygote.Context{false}, ::Main.HRMFluxAddCarry.var\"##_run_sequence_HL!#5\", ::Int64, ::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}, ::typeof(Main.HRMFluxAddCarry._run_sequence_HL!), ::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Matrix{Float32}, ::Matrix{Float32})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [42] _run_sequence_HL!\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_addition_FLUX.jl:249 [inlined]\n",
      " [43] _pullback(::Zygote.Context{false}, ::typeof(Core.kwcall), ::@NamedTuple{N::Int64, cfg::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}}, ::typeof(Main.HRMFluxAddCarry._run_sequence_HL!), ::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Matrix{Float32}, ::Matrix{Float32})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [44] #run_sequence_addcarry!#4\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_addition_FLUX.jl:240 [inlined]\n",
      " [45] _pullback(::Zygote.Context{false}, ::Main.HRMFluxAddCarry.var\"##run_sequence_addcarry!#4\", ::Int64, ::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}, ::typeof(run_sequence_addcarry!), ::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Matrix{Float32}, ::Matrix{Float32})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [46] run_sequence_addcarry!\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/data/hrm_common_addition_FLUX.jl:232 [inlined]\n",
      " [47] _pullback(::Zygote.Context{false}, ::typeof(Core.kwcall), ::@NamedTuple{N::Int64, cfg::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}}, ::typeof(run_sequence_addcarry!), ::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Matrix{Float32}, ::Matrix{Float32})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [48] batch_loss\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/07_addition_carry_FLUX/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X15sZmlsZQ==.jl:54 [inlined]\n",
      " [49] _pullback(::Zygote.Context{false}, ::typeof(batch_loss), ::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, ::Matrix{Int64}, ::Vector{Int64}, ::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [50] #25\n",
      "    @ ~/Documents/repos/JuliaExploreHRM/07_addition_carry_FLUX/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:54 [inlined]\n",
      " [51] _pullback(ctx::Zygote.Context{false}, f::var\"#25#26\"{@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}, Vector{Int64}, Matrix{Int64}}, args::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface2.jl:0\n",
      " [52] pullback(f::Function, cx::Zygote.Context{false}, args::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface.jl:96\n",
      " [53] pullback(f::Function, args::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/55SqB/src/compiler/interface.jl:94\n",
      " [54] train!(name::String, models::@NamedTuple{arch::Symbol, tok_emb::Embedding{Matrix{Float32}}, emb_to_hid::Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}, l_token_from_low::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_task::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, l_token_from_high::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, Lblk::TransformerBlock{Nothing}, Hblk::TransformerBlock{AbsolutePE{Matrix{Float32}}}, post_high::Chain{Tuple{Dense{typeof(gelu_tanh), Matrix{Float32}, Vector{Float32}}}}, fO::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, h_cls::Vector{Float32}}, Xids_tr_A::Matrix{Int64}, y_tr_A::Vector{Int64}, Xids_tr_B::Matrix{Int64}, y_tr_B::Vector{Int64}, Xids_te_ID::Matrix{Int64}, y_te_ID::Vector{Int64}, Xids_te_M::Matrix{Int64}, y_te_M::Vector{Int64}, Xids_te_O::Matrix{Int64}, y_te_O::Vector{Int64}, cfg::@NamedTuple{d_in::Int64, d_hid::Int64, d_out::Int64, N::Int64, T::Int64, batch::Int64, lr::Float64, num_tokens::Int64, d_embed::Int64, l_heads::Int64, l_ff_mult::Int64, h_heads::Int64, h_ff_mult::Int64, dropout::Float64, pad_id::Int64}; epochs_A::Int64, epochs_B::Int64, rng::MersenneTwister)\n",
      "    @ Main ~/Documents/repos/JuliaExploreHRM/07_addition_carry_FLUX/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:54"
     ]
    }
   ],
   "source": [
    "# Cosine schedule for mixing Phase-B into the stream\n",
    "const MIN_MIX_IN_B = 0.10\n",
    "const MAX_MIX_IN_B = 0.60\n",
    "cosine01(t) = 0.5 * (1 .- cos(pi * clamp(t, 0, 1)))\n",
    "\n",
    "mutable struct TrainLog\n",
    "    name::String\n",
    "    epoch::Vector{Int}\n",
    "    pB::Vector{Float64}\n",
    "    loss::Vector{Float64}\n",
    "    acc_id::Vector{Float64}\n",
    "    acc_mid::Vector{Float64}\n",
    "    acc_ood::Vector{Float64}\n",
    "end\n",
    "newlog(name::String) = TrainLog(name, Int[], Float64[], Float64[], Float64[], Float64[], Float64[])\n",
    "function push_epoch!(L::TrainLog; epoch, pB, loss, acc_id, acc_mid, acc_ood)\n",
    "    push!(L.epoch, epoch); push!(L.pB, pB); push!(L.loss, loss)\n",
    "    push!(L.acc_id, acc_id); push!(L.acc_mid, acc_mid); push!(L.acc_ood, acc_ood)\n",
    "end\n",
    "\n",
    "function train!(name::String, models, Xids_tr_A, y_tr_A, Xids_tr_B, y_tr_B,\n",
    "                Xids_te_ID, y_te_ID, Xids_te_M, y_te_M, Xids_te_O, y_te_O,\n",
    "                cfg;\n",
    "                epochs_A::Int, epochs_B::Int, rng::AbstractRNG)\n",
    "\n",
    "    log = newlog(name)\n",
    "\n",
    "    # Optimizer (AdamW if available, else Adam) + gradient clipping\n",
    "    if isdefined(Optimisers, :AdamW)\n",
    "        opt = Optimisers.OptimiserChain(\n",
    "            Optimisers.ClipNorm(1.0),\n",
    "            Optimisers.AdamW(cfg.lr, (0.9, 0.999), 1e-4),\n",
    "        )\n",
    "    else\n",
    "        opt = Optimisers.OptimiserChain(\n",
    "            Optimisers.ClipNorm(1.0),\n",
    "            Optimisers.Adam(cfg.lr),\n",
    "        )\n",
    "    end\n",
    "    opt_state = Optimisers.setup(opt, models)\n",
    "\n",
    "    for epoch in 1:(epochs_A + epochs_B)\n",
    "        pB = (epoch <= epochs_A) ? 0.0 :\n",
    "             (MIN_MIX_IN_B + (MAX_MIX_IN_B - MIN_MIX_IN_B) * cosine01((epoch - epochs_A) / epochs_B))\n",
    "\n",
    "        total_loss = 0.0; batches = 0\n",
    "\n",
    "        for (xb, yb) in each_minibatch_mixed(Xids_tr_A, y_tr_A, Xids_tr_B, y_tr_B;\n",
    "                                             batch=cfg.batch, pB=pB, buckets=6,\n",
    "                                             pad_id=cfg.pad_id, rng=rng)\n",
    "            # keep PAD embedding column neutral\n",
    "            freeze_pad!(models, cfg.pad_id)\n",
    "\n",
    "            L, back = Zygote.pullback(m -> batch_loss(m, xb, yb, cfg), models)\n",
    "            grads = back(one(L))[1]\n",
    "            opt_state, models = Optimisers.update(opt_state, models, grads)\n",
    "\n",
    "            # re-zero PAD column after update\n",
    "            freeze_pad!(models, cfg.pad_id)\n",
    "\n",
    "            total_loss += Float64(L); batches += 1\n",
    "        end\n",
    "\n",
    "        # Evaluate\n",
    "        acc_id  = evaluate_matrix(models, Xids_te_ID, y_te_ID, cfg)\n",
    "        acc_mid = evaluate_matrix(models, Xids_te_M,  y_te_M,  cfg)\n",
    "        acc_ood = evaluate_matrix(models, Xids_te_O,  y_te_O,  cfg)\n",
    "\n",
    "        @info \"$(name) epoch $(epoch)  loss $(round(total_loss/max(batches,1), digits=4))  \" *\n",
    "              \"ID $(round(acc_id,digits=3))  MID $(round(acc_mid,digits=3))  OOD $(round(acc_ood,digits=3))\"\n",
    "\n",
    "        push_epoch!(log; epoch=epoch, pB=pB, loss=total_loss/max(batches,1),\n",
    "                    acc_id=acc_id, acc_mid=acc_mid, acc_ood=acc_ood)\n",
    "    end\n",
    "\n",
    "    return models, log\n",
    "end\n",
    "\n",
    "# ---- Run trainings (analogue to your Dyck workflow) ----\n",
    "epochs_A = 10\n",
    "epochs_B = 20\n",
    "\n",
    "rng_HL = MersenneTwister(13)\n",
    "rng_HH = MersenneTwister(13)\n",
    "\n",
    "models_HL, log_HL = train!(\"H+L\", models_HL,\n",
    "    Xids_tr_A, y_tr_A, Xids_tr_B, y_tr_B,\n",
    "    Xids_te_ID, y_te_ID, Xids_te_M, y_te_M, Xids_te_O, y_te_O,\n",
    "    cfg; epochs_A=epochs_A, epochs_B=epochs_B, rng=rng_HL)\n",
    "\n",
    "models_HH, log_HH = train!(\"H+H\", models_HH,\n",
    "    Xids_tr_A, y_tr_A, Xids_tr_B, y_tr_B,\n",
    "    Xids_te_ID, y_te_ID, Xids_te_M, y_te_M, Xids_te_O, y_te_O,\n",
    "    cfg; epochs_A=epochs_A, epochs_B=epochs_B, rng=rng_HH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01246c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ] add ProgressMeter\n",
    "using ProgressMeter\n",
    "\n",
    "# Replace inner 'for (xb, yb) in ...' loop with:\n",
    "p = Progress(nb_est, 1, show_speed=true)\n",
    "for (xb, yb) in each_minibatch_mixed(...)\n",
    "    # ... same training step body ...\n",
    "    next!(p; showvalues=[(:loss, total_loss/max(batches,1))])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a7dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361079ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee6c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9759f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b979c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b20cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae64dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2e1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a94d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc1d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.9",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
